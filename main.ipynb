{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 – Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 – Generate random data for the social media data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_long = 500\n",
    "\n",
    "categories = [\"Food\", \"Travel\", \"Fashion\", \"Fitness\", \"Music\", \"Culture\", \"Family\", \"Health\"]\n",
    "\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start='2023-01-01', periods=periods_long),\n",
    "    \"Category\": [random.choice(categories) for _ in range(periods_long)],\n",
    "    \"Likes\": np.random.randint(0, 10000, size=periods_long),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 – Load the data into a Pandas DataFrame and Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4 – Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Likes'] = data['Likes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5– Visualize and Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of likes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data['Likes'], kde=True)\n",
    "plt.title('Distribution of Likes')\n",
    "plt.xlabel('Likes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of likes and categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Category', y='Likes', data=data)\n",
    "plt.title('Likes by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Likes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean likes of each category\n",
    "data.groupby('Category')['Likes'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, this jupyter notebook successfully creates a data analysis pipeline for a hypothetical social media dataset. It begins by importing necessary libraries, then generates random data for the dataset. The data is then loaded into a pandas DataFrame for exploration and cleaning. The script checks for missing values and duplicates, and ensures the data types are correct for each column.\n",
    "\n",
    "The data is then visualized using histograms and boxplots, providing insights into the distribution of 'Likes' and the relationship between 'Category' and 'Likes'. The script also calculates the mean 'Likes' for the entire dataset and for each category.\n",
    "\n",
    "This script provides a solid foundation for any further analysis or machine learning tasks. Future work could include more sophisticated data cleaning and preprocessing steps, more in-depth exploratory data analysis, and the application of machine learning algorithms to predict 'Likes' based on 'Category' or other features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
